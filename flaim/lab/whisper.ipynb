{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7885be1",
      "metadata": {
        "id": "e7885be1"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f32e8d5f",
      "metadata": {
        "id": "f32e8d5f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93525c56",
      "metadata": {
        "id": "93525c56"
      },
      "outputs": [],
      "source": [
        "# check \"7. Pipeline.ipynb\"\n",
        "from whisperspeech.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49be72e0",
      "metadata": {
        "id": "49be72e0"
      },
      "outputs": [],
      "source": [
        "# let's start with the fast SD S2A model\n",
        "pipe = Pipeline(s2a_ref='collabora/whisperspeech:s2a-q4-tiny-en+pl.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f760666",
      "metadata": {
        "id": "8f760666",
        "outputId": "35440e72-ca1e-4508-dd2c-65d9b8836cd2"
      },
      "outputs": [],
      "source": [
        "# this is very slow right now since our inference code is not very optimized\n",
        "# but even without this crucial optimization it is still better than real-time on an RTX 4090\n",
        "pipe.generate_to_notebook(\"\"\"\n",
        "This is the first demo of Whisper Speech, a fully open source text-to-speech model trained by Collabora and Lion on the Juwels supercomputer.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b731876d",
      "metadata": {
        "id": "b731876d",
        "outputId": "64462c9d-b2b7-4007-e276-d16760b80880"
      },
      "outputs": [],
      "source": [
        "# The model knows how to speak in Polish\n",
        "pipe.generate_to_notebook(\"\"\"\n",
        "To jest pierwszy test naszego modelu. Pozdrawiamy serdecznie.\n",
        "\"\"\", lang='pl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e856c446",
      "metadata": {
        "id": "e856c446",
        "outputId": "957a82ff-2014-4b2d-ca45-212fa8f3043d"
      },
      "outputs": [],
      "source": [
        "# We can also mix different languages (e.g. for borrowed words) in a single sentence\n",
        "stoks = pipe.t2s.generate([\"To jest pierwszy test wielojęzycznego \", \" Whisper Speech \", \", modelu zamieniającego tekst na mowę, który Collabora i Laion nauczyli na superkomputerze\", \" Jewels.\"], lang=['pl', 'en', 'pl', 'en'])\n",
        "pipe.vocoder.decode_to_notebook(pipe.s2a.generate(stoks, pipe.default_speaker.unsqueeze(0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "731f13e2",
      "metadata": {
        "id": "731f13e2",
        "outputId": "dc0fba00-c4db-4d9b-ad8f-4b24bf2d0721"
      },
      "outputs": [],
      "source": [
        "stoks = pipe.t2s.generate([\"I love to eat eastern european food! Especially \", \"pierogi i bigos.\"], lang=['en', 'pl'], cps=11)\n",
        "pipe.vocoder.decode_to_notebook(pipe.s2a.generate(stoks, pipe.default_speaker.unsqueeze(0)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
