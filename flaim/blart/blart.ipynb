{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from diffusers import (\n",
    "    StableDiffusionXLPipeline,\n",
    "    StableDiffusionLatentUpscalePipeline,\n",
    "    EulerAncestralDiscreteScheduler,\n",
    "    AutoencoderKL,\n",
    "    logging,\n",
    "    StableDiffusionInstructPix2PixPipeline,\n",
    "    StableDiffusion3Pipeline,\n",
    ")\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import sys\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"berlin cathedral in a field\"\n",
    "\n",
    "loaded_prompt = (\n",
    "    \"concept art \"\n",
    "    + prompt\n",
    "    + \", high quality, (magical), (nature), (futuristic), digital artwork, highly detailed\"\n",
    ")\n",
    "\n",
    "loaded_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_prompt = \"nsfw, cartoon, bad quality, bad anatomy, worst quality, low quality, low resolutions, extra fingers, blur, blurry, ugly, wrong proportions, watermark, image artifacts, lowres, ugly, jpeg artifacts, deformed, noisy image\"\n",
    "\n",
    "negative_prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proteus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = AutoencoderKL.from_pretrained(\n",
    "    \"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"dataautogpt3/ProteusV0.4-Lightning\", vae=vae, torch_dtype=torch.float16\n",
    ").to(device)\n",
    "\n",
    "pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protoimages = pipe(\n",
    "    prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    num_images_per_prompt=3,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    guidance_scale=3.5,\n",
    "    num_inference_steps=8,\n",
    ").images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocomp = Image.new(\"RGB\", (3072, 600))\n",
    "\n",
    "x_offset = 0\n",
    "for im in protoimages:\n",
    "    protocomp.paste(im, (x_offset, -212))\n",
    "    x_offset += im.size[0]\n",
    "\n",
    "protocomp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusion3Pipeline.from_pretrained(\"stabilityai/stable-diffusion-3-medium-diffusers\", torch_dtype=torch.float16, token=os.environ.get(\"HF_TOKEN\"))\n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protoimages = pipe(\n",
    "    loaded_prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    num_images_per_prompt=3,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    guidance_scale=7,\n",
    "    num_inference_steps=18,\n",
    ").images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocomp = Image.new(\"RGB\", (3072, 600))\n",
    "\n",
    "x_offset = 0\n",
    "for im in protoimages:\n",
    "    protocomp.paste(im, (x_offset, -212))\n",
    "    x_offset += im.size[0]\n",
    "\n",
    "protocomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 = left \n",
    "# 2 = middle\n",
    "# 3 = right\n",
    "chosenimage = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruct pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"timbrooks/instruct-pix2pix\"\n",
    "pipe = StableDiffusionInstructPix2PixPipeline.from_pretrained(\n",
    "    model_id, torch_dtype=torch.float16, safety_checker=None\n",
    ")\n",
    "pipe.to(device)\n",
    "pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"amazing, high quality, dreamlike, futuristic, colorful, vibrant\"\n",
    "# prompt = \"make image air brushed, painted, gradients\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    image=protoimages[chosenimage-1],\n",
    "    num_inference_steps=15,\n",
    "    image_guidance_scale=1,\n",
    ").images[0]\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Garbage collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = None\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "if device == \"mps\":\n",
    "    torch.mps.empty_cache()\n",
    "    torch.mps.current_allocated_memory()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upscaler = StableDiffusionLatentUpscalePipeline.from_pretrained(\n",
    "    \"stabilityai/sd-x2-latent-upscaler\", torch_dtype=torch.float16\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upscaled_image = upscaler(\n",
    "    prompt=loaded_prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    image=image,\n",
    "    num_inference_steps=20,\n",
    "    guidance_scale=0,\n",
    ").images[0]\n",
    "\n",
    "upscaled_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image = upscaled_image.crop(\n",
    "    (24, 424, 2024, 1624)\n",
    ")  # from 2048/1024 to 2000/1200\n",
    "\n",
    "cropped_image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
